The name of this project is really a misnomer. Initially this project
was concerned with finding a robust way to gather OHLCV bars on on
trading days. There are several "free" data-sources available: yahoo
finance, Google finance, and TDameritrade (which is not exactly free
-- you have to have an account). Since we did have a Tdameritrade
account we used their data-source because we could not only get daily
bar but also intraday bars at 5,10, 15,30, minute
intervals. TDameritrade also had a "live" feed where we could easily
get snapshot information down to the minute. They also offer Level I
and Level II streams. This is where the "capture" term in the project
came from. The project grew from that very quickly into one where we
could design strategies, backtest them over the 10 years of daily bars
we had in the DB form which a sequence of positions were generated,
the opening and closing of which was determined by the strategy being
used for backtesting purposes.

A collection of positions is not quite enough information to simulate
an actual trading strategy. A collection of Positions does not include
real-life limitation like the amount of money available to invest on
any given day, nor the investment meta-strategy where returns are
re-invested into the market as opposed to taking the ROI out in cash
to produce an income. Doing so, obviously, does not allow for any
compounding of funds, but in real life that may be a requirement.

In the end the stock_db_capture was designed to:

1.Capture Daily and Intraday data on a regular basis (via cron running
  rake tasks)

2.Support the design of trading strategies of arbitrary complexity and
  the backtesting of them

3.From the collection of positions generated in #2, simulate the
  execution of trades using finite resources

4.Provide for a "stock watcher" which triggered entries on a list of
  stocks which met a certain criterion from which a user could open a
  position, which would then be watched to see when the closing criteria
  was met.

5.The results from backtest could also be feed into R to produce
  wonderful graphs which helped "tune" the strategy.

6.Several months of "paper trading" using an RSI/RVI driven strategy
  produced favorable results but the evolving ROI was still victim to
  overall market sentiment.

The backtester was the utility which went though the most change
throughout the project. Initially it relied on a DSL which make
defining strategies really easily, but the kinds of strategies were
limited.

Once it was recognized that this was a serious limitation of the
backtest I went with a message passing architecture. Numerous
frameworks were used to facilitate the message passing protocol. They
were in order:

1.Rinda -- simple, reliable, and slow. The deal-breaker came when the
  Ring Finger was unable to locate a tuple-server anymore.

2.EventMachine + RabbitMQ -- relatively simple, advertised as
  reliable, but way too slow for our needs. The RabbitMQ server would
  become simply overwhelmed at a message publishing rate of less the
  100ms/message.

3.EventMachine + Beanstalk - fast, reliable but had some quicks, most
  likely due to the rather unsophisticated EM-Jack layer. The end result
  was lost messages which was intolerable. Backtests HAVE to be
  repeatable to be of any use whatsoever.

4.A synchronous version of the Beanstalk protocol resting upon
  beanstalk-client library which is a synchronous library. The proved
  stable yet under certain (often) conditions it would lose the first 12
  messages generated from the producer/consumers. This was a consistent
  pattern.

5.Which leads to the present, we do not have a message-based
  backtester that is robust. It is my hope that somebody who know
  EventMachine much better than I will be able to suss this out. Trying
  to debug this using ruby-1.9.2 w/o a debugger proved to by a
  nightmare. The symptoms are that when as the body of a task (a task is
  a stage in a multistage strategy where each stage computes something
  and passes on to the next stage)is executed on a 'defer' to a
  theadpool, the completion callback is never call...but only for 12
  messages which is not a magic number. The number of threads in the
  pool is 20.

To begin any serious work on this project you will need to populate your DB.
I am using MySQL and can provide dumps of all the relevant tables. Since
this is my first github project, I don't know th policy of upload huge
sql dump files.


Best Regards,

Kevin Nolan
kpnolan@comcast.net

